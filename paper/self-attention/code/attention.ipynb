{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# 打印当前选择的GPU\n",
    "print(f\"Using GPU:{os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da020dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "import math\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c210ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(128, 64, 512).to(device) # Batch, Token, Dimension\n",
    "# 128个句子，64个词元，512维的词向量\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cadb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "n_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff611fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.6273e-02,  4.7680e-02,  1.2444e-01,  ...,  1.6692e-01,\n",
      "          -3.4143e-01,  1.9715e-01],\n",
      "         [ 4.3156e-01, -2.4046e-01, -7.2708e-02,  ..., -1.4109e-01,\n",
      "          -2.5770e-01,  1.9147e-01],\n",
      "         [ 3.9320e-01, -1.0397e-01, -1.0461e-01,  ...,  7.1226e-02,\n",
      "          -2.4283e-01,  1.0542e-01],\n",
      "         ...,\n",
      "         [-2.3892e-02, -6.2497e-02,  3.2211e-03,  ..., -5.3380e-03,\n",
      "          -4.2989e-02,  2.6861e-02],\n",
      "         [-1.1776e-02, -8.4258e-02,  2.9447e-02,  ...,  1.0789e-02,\n",
      "          -4.2125e-02, -3.4765e-04],\n",
      "         [-7.7546e-03, -8.0037e-02, -3.0760e-02,  ...,  1.8437e-02,\n",
      "          -6.0307e-02,  1.4884e-02]],\n",
      "\n",
      "        [[ 2.4255e-01,  1.8704e-01, -3.8051e-01,  ...,  3.9135e-01,\n",
      "          -1.1913e-01,  2.1020e-01],\n",
      "         [ 1.0736e-01,  1.4980e-01, -3.5683e-01,  ..., -1.0606e-01,\n",
      "          -2.5445e-01,  3.0958e-01],\n",
      "         [ 5.3697e-02, -2.9903e-02, -2.4500e-01,  ...,  7.5165e-02,\n",
      "          -1.2057e-01,  3.3893e-01],\n",
      "         ...,\n",
      "         [ 2.1646e-02, -9.9663e-02,  2.8562e-02,  ..., -2.2616e-02,\n",
      "          -7.1142e-02, -5.2743e-02],\n",
      "         [ 1.6873e-02, -6.2655e-02,  3.3305e-02,  ..., -1.8157e-02,\n",
      "          -4.1322e-02, -5.7045e-02],\n",
      "         [ 5.1635e-02, -7.2193e-02,  9.3096e-03,  ...,  1.6934e-02,\n",
      "          -1.4173e-02, -3.7246e-02]],\n",
      "\n",
      "        [[ 9.5169e-02, -8.4504e-01,  9.5277e-02,  ..., -3.2486e-01,\n",
      "          -1.9921e-01, -1.8496e-01],\n",
      "         [ 1.1339e-01, -5.1485e-01,  5.0098e-01,  ..., -1.7435e-01,\n",
      "           3.7823e-02, -1.8224e-01],\n",
      "         [ 1.3347e-01, -3.9690e-01,  3.7844e-01,  ..., -1.7710e-01,\n",
      "          -1.0057e-01, -1.7833e-01],\n",
      "         ...,\n",
      "         [-6.1167e-03, -1.6880e-01,  1.9801e-03,  ..., -7.1402e-03,\n",
      "          -3.3006e-02, -6.1485e-04],\n",
      "         [-3.4684e-02, -1.6553e-01, -2.0683e-02,  ..., -7.1986e-03,\n",
      "          -2.8418e-02, -3.6914e-03],\n",
      "         [-1.4438e-02, -1.3108e-01, -1.6885e-02,  ...,  1.0827e-02,\n",
      "          -1.4939e-02, -3.1911e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.0327e-01, -5.6962e-01,  1.5208e-01,  ..., -3.4938e-01,\n",
      "           3.7401e-01,  2.2842e-01],\n",
      "         [-4.4917e-02, -5.4238e-01,  1.3535e-01,  ..., -2.4120e-01,\n",
      "           1.6359e-01,  6.5058e-02],\n",
      "         [-1.1720e-01, -1.6577e-01, -1.1227e-01,  ..., -3.7082e-01,\n",
      "           8.5800e-02, -1.6105e-01],\n",
      "         ...,\n",
      "         [-2.2082e-02, -5.1219e-02, -2.9898e-02,  ..., -3.1825e-02,\n",
      "          -5.5523e-02, -8.9759e-02],\n",
      "         [-1.2245e-02, -4.7049e-02, -2.2357e-02,  ..., -2.2057e-02,\n",
      "          -1.9622e-02, -7.2743e-02],\n",
      "         [-2.9171e-02, -4.4925e-02,  9.6836e-03,  ..., -2.7153e-02,\n",
      "          -2.1363e-02, -6.2166e-02]],\n",
      "\n",
      "        [[-3.2155e-01,  2.3243e-01, -1.4817e-01,  ...,  4.6744e-01,\n",
      "           4.0586e-02,  3.7320e-02],\n",
      "         [-1.9074e-01,  1.6575e-01, -7.6876e-02,  ...,  5.2122e-01,\n",
      "           2.0905e-01, -4.7612e-02],\n",
      "         [-1.5300e-01,  4.4399e-02,  1.6367e-02,  ...,  4.1019e-01,\n",
      "          -1.1612e-02, -1.9086e-01],\n",
      "         ...,\n",
      "         [-4.3279e-02, -1.0629e-01,  3.5394e-02,  ..., -2.3813e-02,\n",
      "          -5.1721e-02, -2.3714e-02],\n",
      "         [-4.1884e-02, -6.8159e-02,  6.5399e-02,  ..., -2.8849e-02,\n",
      "          -6.5785e-02, -5.4380e-02],\n",
      "         [-6.1162e-02, -9.4334e-02,  3.6892e-02,  ...,  3.2503e-03,\n",
      "          -5.7116e-02, -2.5408e-02]],\n",
      "\n",
      "        [[ 4.9543e-01,  7.5089e-01, -3.5429e-01,  ...,  2.2021e-01,\n",
      "          -2.5373e-01, -2.0854e-01],\n",
      "         [ 2.4905e-01,  5.2856e-01, -7.4274e-02,  ..., -6.6510e-03,\n",
      "          -3.4801e-02, -1.0202e-02],\n",
      "         [ 2.0084e-01,  3.0557e-01, -6.6789e-02,  ..., -4.6500e-03,\n",
      "          -7.6034e-02,  1.5440e-01],\n",
      "         ...,\n",
      "         [ 4.7344e-02, -3.8810e-02,  4.6330e-02,  ...,  2.3025e-02,\n",
      "           2.6954e-03,  3.9932e-02],\n",
      "         [ 1.7142e-02, -4.8306e-02,  4.9388e-02,  ...,  1.4252e-02,\n",
      "           2.1751e-02,  2.8561e-02],\n",
      "         [ 2.4802e-02, -2.5067e-02,  6.6402e-03,  ..., -7.1358e-03,\n",
      "           7.1575e-03,  2.9445e-02]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) torch.Size([128, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "class multi_head_attention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        # q, k, v: [batch_size, seq_len, d_model]\n",
    "        batch, token, dimensiton = q.shape # 128, 64, 512\n",
    "        n_d = self.d_model // self.n_head # 512 // 8 = 64\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        \n",
    "        q = q.view(batch, token, self.n_head, n_d).permute(0,2,1,3) #[batch, token, head, d] to [batch, head, token, d]\n",
    "        k = k.view(batch, token, self.n_head, n_d).permute(0,2,1,3)\n",
    "        v = v.view(batch, token, self.n_head, n_d).permute(0,2,1,3)\n",
    "        \n",
    "        #[a, b] @ [b, c] → [a, c]\n",
    "        # score = q @ k.transpose(2,3) / math.sqrt(n_d)\n",
    "        score = q @ k.transpose(-2,-1) / math.sqrt(n_d) # [batch, head, token, d_k] * [batch, head, d_k, token]\n",
    "        mask = torch.tril(torch.ones(token,token,dtype=torch.bool, device=q.device))\n",
    "        # score = score.masked_fill(mask == 0, -1e9)\n",
    "        score = score.masked_fill(mask == 0, float('-inf'))\n",
    "        score = self.softmax(score) @ v\n",
    "        \n",
    "        score = score.permute(0,2,1,3).contiguous().view(batch, token, dimensiton)\n",
    "        \n",
    "        output = self.w_combine(score)\n",
    "        return output\n",
    "        \n",
    "attention = multi_head_attention(d_model, n_heads).to(device)\n",
    "output = attention(X, X, X)\n",
    "print(output, output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f52df",
   "metadata": {},
   "source": [
    "self-attention 就是 input 一排Vector 然后 output 一排 Vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
