{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1df913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quality</th>\n",
       "      <th>#1 ID</th>\n",
       "      <th>#2 ID</th>\n",
       "      <th>#1 String</th>\n",
       "      <th>#2 String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>702876</td>\n",
       "      <td>702977</td>\n",
       "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
       "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2108705</td>\n",
       "      <td>2108831</td>\n",
       "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
       "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1330381</td>\n",
       "      <td>1330521</td>\n",
       "      <td>They had published an advertisement on the Int...</td>\n",
       "      <td>On June 10, the ship's owners had published an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3344667</td>\n",
       "      <td>3344648</td>\n",
       "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
       "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1236820</td>\n",
       "      <td>1236712</td>\n",
       "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
       "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>1620264</td>\n",
       "      <td>1620507</td>\n",
       "      <td>\"At this point, Mr. Brando announced: 'Somebod...</td>\n",
       "      <td>Brando said that \"somebody ought to put a bull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>0</td>\n",
       "      <td>1848001</td>\n",
       "      <td>1848224</td>\n",
       "      <td>Martin, 58, will be freed today after serving ...</td>\n",
       "      <td>Martin served two thirds of a five-year senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>747160</td>\n",
       "      <td>747144</td>\n",
       "      <td>\"We have concluded that the outlook for price ...</td>\n",
       "      <td>In a statement, the ECB said the outlook for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>2539933</td>\n",
       "      <td>2539850</td>\n",
       "      <td>The notification was first reported Friday by ...</td>\n",
       "      <td>MSNBC.com first reported the CIA request on Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>0</td>\n",
       "      <td>453575</td>\n",
       "      <td>453448</td>\n",
       "      <td>The 30-year bond US30YT=RR rose 22/32 for a yi...</td>\n",
       "      <td>The 30-year bond US30YT=RR grew 1-3/32 for a y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4076 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Quality    #1 ID    #2 ID  \\\n",
       "0           1   702876   702977   \n",
       "1           0  2108705  2108831   \n",
       "2           1  1330381  1330521   \n",
       "3           0  3344667  3344648   \n",
       "4           1  1236820  1236712   \n",
       "...       ...      ...      ...   \n",
       "4071        1  1620264  1620507   \n",
       "4072        0  1848001  1848224   \n",
       "4073        1   747160   747144   \n",
       "4074        1  2539933  2539850   \n",
       "4075        0   453575   453448   \n",
       "\n",
       "                                              #1 String  \\\n",
       "0     Amrozi accused his brother, whom he called \"th...   \n",
       "1     Yucaipa owned Dominick's before selling the ch...   \n",
       "2     They had published an advertisement on the Int...   \n",
       "3     Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
       "4     The stock rose $2.11, or about 11 percent, to ...   \n",
       "...                                                 ...   \n",
       "4071  \"At this point, Mr. Brando announced: 'Somebod...   \n",
       "4072  Martin, 58, will be freed today after serving ...   \n",
       "4073  \"We have concluded that the outlook for price ...   \n",
       "4074  The notification was first reported Friday by ...   \n",
       "4075  The 30-year bond US30YT=RR rose 22/32 for a yi...   \n",
       "\n",
       "                                              #2 String  \n",
       "0     Referring to him as only \"the witness\", Amrozi...  \n",
       "1     Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
       "2     On June 10, the ship's owners had published an...  \n",
       "3     Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
       "4     PG&E Corp. shares jumped $1.63 or 8 percent to...  \n",
       "...                                                 ...  \n",
       "4071  Brando said that \"somebody ought to put a bull...  \n",
       "4072  Martin served two thirds of a five-year senten...  \n",
       "4073  In a statement, the ECB said the outlook for p...  \n",
       "4074  MSNBC.com first reported the CIA request on Fr...  \n",
       "4075  The 30-year bond US30YT=RR grew 1-3/32 for a y...  \n",
       "\n",
       "[4076 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 数据读取\n",
    "data = pd.read_csv('./data/msr_paraphrase_train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db9e89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>same</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>amrozi accused his brother whom he called the ...</td>\n",
       "      <td>referring to him as only the witness amrozi ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>yucaipa owned dominick s before selling the ch...</td>\n",
       "      <td>yucaipa bought dominick s in &lt;NUM&gt; for &lt;NUM&gt; m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>they had published an advertisement on the int...</td>\n",
       "      <td>on june &lt;NUM&gt; the ship s owners had published ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>around &lt;NUM&gt; gmt tab shares were up &lt;NUM&gt; cent...</td>\n",
       "      <td>tab shares jumped &lt;NUM&gt; cents or &lt;NUM&gt; &lt;NUM&gt; t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>the stock rose &lt;NUM&gt; &lt;NUM&gt; or about &lt;NUM&gt; perc...</td>\n",
       "      <td>pg e corp shares jumped &lt;NUM&gt; &lt;NUM&gt; or &lt;NUM&gt; p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>at this point mr brando announced somebody oug...</td>\n",
       "      <td>brando said that somebody ought to put a bulle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>0</td>\n",
       "      <td>martin &lt;NUM&gt; will be freed today after serving...</td>\n",
       "      <td>martin served two thirds of a five year senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>we have concluded that the outlook for price s...</td>\n",
       "      <td>in a statement the ecb said the outlook for pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>the notification was first reported friday by ...</td>\n",
       "      <td>msnbc com first reported the cia request on fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>0</td>\n",
       "      <td>the &lt;NUM&gt; year bond us &lt;NUM&gt; yt rr rose &lt;NUM&gt; ...</td>\n",
       "      <td>the &lt;NUM&gt; year bond us &lt;NUM&gt; yt rr grew &lt;NUM&gt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4076 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      same                                                 s1  \\\n",
       "0        1  amrozi accused his brother whom he called the ...   \n",
       "1        0  yucaipa owned dominick s before selling the ch...   \n",
       "2        1  they had published an advertisement on the int...   \n",
       "3        0  around <NUM> gmt tab shares were up <NUM> cent...   \n",
       "4        1  the stock rose <NUM> <NUM> or about <NUM> perc...   \n",
       "...    ...                                                ...   \n",
       "4071     1  at this point mr brando announced somebody oug...   \n",
       "4072     0  martin <NUM> will be freed today after serving...   \n",
       "4073     1  we have concluded that the outlook for price s...   \n",
       "4074     1  the notification was first reported friday by ...   \n",
       "4075     0  the <NUM> year bond us <NUM> yt rr rose <NUM> ...   \n",
       "\n",
       "                                                     s2  \n",
       "0     referring to him as only the witness amrozi ac...  \n",
       "1     yucaipa bought dominick s in <NUM> for <NUM> m...  \n",
       "2     on june <NUM> the ship s owners had published ...  \n",
       "3     tab shares jumped <NUM> cents or <NUM> <NUM> t...  \n",
       "4     pg e corp shares jumped <NUM> <NUM> or <NUM> p...  \n",
       "...                                                 ...  \n",
       "4071  brando said that somebody ought to put a bulle...  \n",
       "4072  martin served two thirds of a five year senten...  \n",
       "4073  in a statement the ecb said the outlook for pr...  \n",
       "4074  msnbc com first reported the cia request on fr...  \n",
       "4075  the <NUM> year bond us <NUM> yt rr grew <NUM> ...  \n",
       "\n",
       "[4076 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除多余列\n",
    "data.pop('#1 ID')\n",
    "data.pop('#2 ID')\n",
    "\n",
    "# 重命名列\n",
    "columns = list(data.columns)\n",
    "columns[0] = 'same'\n",
    "columns[1] = 's1'\n",
    "columns[2] = 's2'\n",
    "\n",
    "data.columns = columns\n",
    "\n",
    "# 清洗标点符号\n",
    "data['s1'] = data['s1'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "data['s2'] = data['s2'].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
    "\n",
    "# 处理特殊字符\n",
    "data['s1'] = data['s1'].str.replace('â', 'a')\n",
    "data['s1'] = data['s1'].str.replace('Â', 'A')\n",
    "data['s1'] = data['s1'].str.replace('Ã', 'A')\n",
    "data['s1'] = data['s1'].str.replace('_', ' ')\n",
    "data['s1'] = data['s1'].str.replace('μ', 'u')\n",
    "data['s1'] = data['s1'].str.replace('ε', ' ')\n",
    "data['s1'] = data['s1'].str.replace('½', ' ')\n",
    "data['s2'] = data['s2'].str.replace('â', 'a')\n",
    "data['s2'] = data['s2'].str.replace('Â', 'A')\n",
    "data['s2'] = data['s2'].str.replace('Ã', 'A')\n",
    "data['s2'] = data['s2'].str.replace('_', ' ')\n",
    "data['s2'] = data['s2'].str.replace('μ', 'u')\n",
    "data['s2'] = data['s2'].str.replace('ε', ' ')\n",
    "data['s2'] = data['s2'].str.replace('½', ' ')\n",
    "\n",
    "# 合并连续空格\n",
    "data['s1'] = data['s1'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "data['s2'] = data['s2'].str.replace(r'\\s{2,}', ' ', regex=True)\n",
    "\n",
    "# 拆分数字与字母连写的词\n",
    "data['s1'] = data['s1'].str.replace(r'(\\d)([a-zA-Z])', '\\\\1 \\\\2', regex=True)\n",
    "data['s2'] = data['s2'].str.replace(r'(\\d)([a-zA-Z])', '\\\\1 \\\\2', regex=True)\n",
    "data['s1'] = data['s1'].str.replace(r'([a-zA-Z])(\\d)', '\\\\1 \\\\2', regex=True)\n",
    "data['s2'] = data['s2'].str.replace(r'([a-zA-Z])(\\d)', '\\\\1 \\\\2', regex=True)\n",
    "\n",
    "# 删除首尾空格并小写所有字母\n",
    "data['s1'] = data['s1'].str.strip()\n",
    "data['s1'] = data['s1'].str.lower()\n",
    "data['s2'] = data['s2'].str.strip()\n",
    "data['s2'] = data['s2'].str.lower()\n",
    "\n",
    "# 替换数字为符号\n",
    "data['s1'] = data['s1'].str.replace(r'\\d+', '<NUM>', regex=True)\n",
    "data['s2'] = data['s2'].str.replace(r'\\d+', '<NUM>', regex=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c280ff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加首尾符号\n",
    "def f1(sent):\n",
    "    return '<SOS> ' + sent + ' <EOS>' \n",
    "\n",
    "data['s1'] = data['s1'].apply(f1)\n",
    "\n",
    "def f2(sent):\n",
    "    return sent + ' <EOS>' \n",
    "\n",
    "data['s2'] = data['s2'].apply(f2)\n",
    "\n",
    "# 计算句子长度\n",
    "def f3(sent):\n",
    "    return len(sent.split(' '))\n",
    "\n",
    "data['s1_lens'] = data['s1'].apply(f3)\n",
    "data['s2_lens'] = data['s2'].apply(f3)\n",
    "\n",
    "# 计算最长合并序列\n",
    "max_lens = max(data['s1_lens'] + data['s2_lens'])\n",
    "max_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bd252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>same</th>\n",
       "      <th>s1_lens</th>\n",
       "      <th>s2_lens</th>\n",
       "      <th>pad_lens</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>&lt;SOS&gt; amrozi accused his brother whom he calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>&lt;SOS&gt; yucaipa owned dominick s before selling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;SOS&gt; they had published an advertisement on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;SOS&gt; around &lt;NUM&gt; gmt tab shares were up &lt;NUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>&lt;SOS&gt; the stock rose &lt;NUM&gt; &lt;NUM&gt; or about &lt;NUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>&lt;SOS&gt; at this point mr brando announced somebo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>&lt;SOS&gt; martin &lt;NUM&gt; will be freed today after s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;SOS&gt; we have concluded that the outlook for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>&lt;SOS&gt; the notification was first reported frid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;SOS&gt; the &lt;NUM&gt; year bond us &lt;NUM&gt; yt rr rose ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4076 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      same  s1_lens  s2_lens  pad_lens  \\\n",
       "0        1       16       17        39   \n",
       "1        0       18       21        33   \n",
       "2        1       20       20        32   \n",
       "3        0       28       19        25   \n",
       "4        1       23       22        27   \n",
       "...    ...      ...      ...       ...   \n",
       "4071     1       20       17        35   \n",
       "4072     0       26       19        27   \n",
       "4073     1       28       29        15   \n",
       "4074     1       10       10        52   \n",
       "4075     0       28       27        17   \n",
       "\n",
       "                                                   sent  \n",
       "0     <SOS> amrozi accused his brother whom he calle...  \n",
       "1     <SOS> yucaipa owned dominick s before selling ...  \n",
       "2     <SOS> they had published an advertisement on t...  \n",
       "3     <SOS> around <NUM> gmt tab shares were up <NUM...  \n",
       "4     <SOS> the stock rose <NUM> <NUM> or about <NUM...  \n",
       "...                                                 ...  \n",
       "4071  <SOS> at this point mr brando announced somebo...  \n",
       "4072  <SOS> martin <NUM> will be freed today after s...  \n",
       "4073  <SOS> we have concluded that the outlook for p...  \n",
       "4074  <SOS> the notification was first reported frid...  \n",
       "4075  <SOS> the <NUM> year bond us <NUM> yt rr rose ...  \n",
       "\n",
       "[4076 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个句子需要补充的<PAD>数量\n",
    "data['pad_lens'] = 72 - data['s1_lens'] - data['s2_lens']\n",
    "\n",
    "# 合并s1与s2\n",
    "data['sent'] = data['s1'] + ' ' + data['s2']\n",
    "data.pop('s1')\n",
    "data.pop('s2')\n",
    "\n",
    "# 补充<PAD>\n",
    "def f4(row):\n",
    "    pad = ' '.join(['<PAD>'] * row['pad_lens'])\n",
    "    row['sent'] = row['sent'] + ' ' + pad\n",
    "    return row\n",
    "\n",
    "data = data.apply(f4, axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e212da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12397"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建字典\n",
    "def build_vocab(data):\n",
    "    vocab = {\n",
    "        '<PAD>': 0,\n",
    "        '<SOS>': 1,\n",
    "        '<EOS>': 2,\n",
    "        '<NUM>': 3,\n",
    "        '<UNK>': 4,\n",
    "        '<MASK>': 5,\n",
    "        '<SYMBOL6>': 6,\n",
    "        '<SYMBOL7>': 7,\n",
    "        '<SYMBOL8>': 8,\n",
    "        '<SYMBOL9>': 9,\n",
    "        '<SYMBOL10>': 10,\n",
    "    }\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for word in data.iloc[i]['sent'].split(' '):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "        \n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(data)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d1762e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>same</th>\n",
       "      <th>s1_lens</th>\n",
       "      <th>s2_lens</th>\n",
       "      <th>pad_lens</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>1,11,12,13,14,15,16,17,18,19,20,21,22,13,23,2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>1,29,30,31,32,33,34,18,35,25,36,37,3,38,3,3,39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>1,45,46,47,48,49,50,18,51,50,52,3,53,18,54,38,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>1,60,3,61,62,63,64,65,3,66,67,3,3,68,69,3,3,70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>1,18,77,78,3,3,67,79,3,80,25,81,82,68,3,3,50,1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>1,68,590,825,198,12392,474,8645,6910,25,408,69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>1,8226,3,237,398,2987,331,427,1284,299,4530,20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>1,1058,479,3952,119,18,5505,38,1856,10622,100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>1,18,9722,174,90,576,82,128,11973,2,11973,2543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>1,18,3,92,3466,586,3,3467,3468,78,3,3,38,69,12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4076 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      same  s1_lens  s2_lens  pad_lens  \\\n",
       "0        1       16       17        39   \n",
       "1        0       18       21        33   \n",
       "2        1       20       20        32   \n",
       "3        0       28       19        25   \n",
       "4        1       23       22        27   \n",
       "...    ...      ...      ...       ...   \n",
       "4071     1       20       17        35   \n",
       "4072     0       26       19        27   \n",
       "4073     1       28       29        15   \n",
       "4074     1       10       10        52   \n",
       "4075     0       28       27        17   \n",
       "\n",
       "                                                   sent  \n",
       "0     1,11,12,13,14,15,16,17,18,19,20,21,22,13,23,2,...  \n",
       "1     1,29,30,31,32,33,34,18,35,25,36,37,3,38,3,3,39...  \n",
       "2     1,45,46,47,48,49,50,18,51,50,52,3,53,18,54,38,...  \n",
       "3     1,60,3,61,62,63,64,65,3,66,67,3,3,68,69,3,3,70...  \n",
       "4     1,18,77,78,3,3,67,79,3,80,25,81,82,68,3,3,50,1...  \n",
       "...                                                 ...  \n",
       "4071  1,68,590,825,198,12392,474,8645,6910,25,408,69...  \n",
       "4072  1,8226,3,237,398,2987,331,427,1284,299,4530,20...  \n",
       "4073  1,1058,479,3952,119,18,5505,38,1856,10622,100,...  \n",
       "4074  1,18,9722,174,90,576,82,128,11973,2,11973,2543...  \n",
       "4075  1,18,3,92,3466,586,3,3467,3468,78,3,3,38,69,12...  \n",
       "\n",
       "[4076 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用字典完成sent编码\n",
    "def f5(sent):\n",
    "    sent = [str(vocab[word]) for word in sent.split(' ')]\n",
    "    sent = ','.join(sent)\n",
    "    return sent\n",
    "\n",
    "data['sent'] = data['sent'].apply(f5)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97611ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储字典与编码文件\n",
    "data.to_csv('./data/msr_paraphrase_train_encoded.csv')\n",
    "pd.DataFrame(vocab.items(), columns=['word', 'token']).to_csv('./data/msr_paraphrase_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6915b548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        token\n",
       " word         \n",
       " <PAD>       0\n",
       " <SOS>       1\n",
       " <EOS>       2\n",
       " <NUM>       3\n",
       " <UNK>       4\n",
       " ...       ...\n",
       " brando  12392\n",
       " fred    12393\n",
       " barras  12394\n",
       " fearon  12395\n",
       " medium  12396\n",
       " \n",
       " [12397 rows x 1 columns],\n",
       "          word\n",
       " token        \n",
       " 0       <PAD>\n",
       " 1       <SOS>\n",
       " 2       <EOS>\n",
       " 3       <NUM>\n",
       " 4       <UNK>\n",
       " ...       ...\n",
       " 12392  brando\n",
       " 12393    fred\n",
       " 12394  barras\n",
       " 12395  fearon\n",
       " 12396  medium\n",
       " \n",
       " [12397 rows x 1 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载字典\n",
    "vocab = pd.read_csv('./data/msr_paraphrase_vocab.csv',index_col='word')\n",
    "vocab_r = pd.read_csv('./data/msr_paraphrase_vocab.csv',index_col='token')\n",
    "vocab, vocab_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf189960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4076,\n",
       " Unnamed: 0                                                    0\n",
       " same                                                          1\n",
       " s1_lens                                                      16\n",
       " s2_lens                                                      17\n",
       " pad_lens                                                     39\n",
       " sent          1,11,12,13,14,15,16,17,18,19,20,21,22,13,23,2,...\n",
       " Name: 0, dtype: object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "# 定义数据集类\n",
    "class MsrDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        data = pd.read_csv('./data/msr_paraphrase_train_encoded.csv')\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]\n",
    "\n",
    "dataset = MsrDataset()\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da9730d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/cz47xs896951dv9kqg0_0b9h0000gn/T/ipykernel_76318/215726546.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  sent = torch.LongTensor(sent)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2, 72]), torch.Size([2, 72]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 数据整理\n",
    "def collate_fn(data):\n",
    "    # 取出数据\n",
    "    same = [i['same'] for i in data]\n",
    "    sent = [i['sent'] for i in data]\n",
    "    s1_lens = [i['s1_lens'] for i in data]\n",
    "    s2_lens = [i['s2_lens'] for i in data]\n",
    "    pad_lens = [i['pad_lens'] for i in data]\n",
    "\n",
    "    # 标识两个句子的位置与<PAD>的位置\n",
    "    seg = []\n",
    "    for i in range(len(sent)):\n",
    "        seg.append([1] * s1_lens[i] + [2] * s2_lens[i] + [0] * pad_lens[i])\n",
    "\n",
    "    sent = [np.array(i.split(','), dtype=int) for i in sent]\n",
    "    same = torch.LongTensor(same)\n",
    "    sent = torch.LongTensor(sent)\n",
    "    seg = torch.LongTensor(seg)\n",
    "\n",
    "    return same, sent, seg\n",
    "\n",
    "test_same, test_sent, test_seg = collate_fn([dataset[0], dataset[1]])\n",
    "test_same.shape, test_sent.shape, test_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a98a321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1570fba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 1]),\n",
       " torch.Size([32, 72]),\n",
       " torch.Size([32, 72]),\n",
       " tensor([   1,   18, 3603,   20,  704, 3604, 2011, 3605, 3606,    3,   42, 3607,\n",
       "         3210, 3608, 2148,    3,   64, 3609,   94, 3610, 3611, 2857, 3612, 1359,\n",
       "          429,  672,    2, 3605, 3613, 3606,    3,   42, 3607, 3210, 3608, 2148,\n",
       "            3, 1314,  145,  431,   27,  588,   50,  988,   94, 3607,   50, 3611,\n",
       "         2857, 3612,   37,   18, 3614, 1389,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查数据样例\n",
    "for i, (test_same, test_sent, test_seg) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "test_same, test_sent.shape, test_seg.shape, test_sent[0], test_seg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c7ba0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 72]),\n",
       " torch.Size([32, 72]),\n",
       " tensor([    1,    18,     5,     5,     5,  3604,  2011,  3605,  3606,     3,\n",
       "             5,  3607,  3210,  3608,  2148,     3,    64,  3609,    94,  3610,\n",
       "          3611,  3399,     5,  1359, 12366,     5,     2,  3605,  3613,  3606,\n",
       "             3,    42,  3607,  3210,  3608,  2148,     3,  1314,   145,   431,\n",
       "             5,   588,    50,   988,    94,  3607,    50,  3611,     5,  3612,\n",
       "            37,    18,  3614,  1389,     2,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " tensor([False, False,  True,  True,  True, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True,  True, False,  True,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "          True, False, False, False, False, False, False, False,  True, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# 随机替换函数\n",
    "def random_replace(sent):\n",
    "    # sent = [b, 72]\n",
    "    sent = sent.clone()\n",
    "\n",
    "    # 标记替换位置（True为该位置进行了替换）\n",
    "    replace = sent == -1\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        for j in range(len(sent[i])):\n",
    "            # 不替换特殊符号\n",
    "            if sent[i, j] <= 10:\n",
    "                continue\n",
    "            if random.random() > 0.15:\n",
    "                continue\n",
    "            # 标记替换位置\n",
    "            replace[i, j] = True\n",
    "            # 概率操作\n",
    "            p = random.random()\n",
    "            # 0.8替换为<MASK>\n",
    "            if p < 0.8:\n",
    "                sent[i, j] = vocab.loc['<MASK>'].token\n",
    "            # 0.1不做改变\n",
    "            elif p < 0.9:\n",
    "                continue\n",
    "            # 0.1 替换成随机词\n",
    "            else:\n",
    "                random_word = 0\n",
    "                while random_word <= 0:\n",
    "                    random_word = random.randint(0, len(vocab) - 1)\n",
    "                sent[i, j] = random_word\n",
    "\n",
    "    return sent, replace\n",
    "\n",
    "replace_sent, replace = random_replace(test_sent)\n",
    "replace_sent.shape, replace.shape, replace_sent[0], replace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4485e0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 72]),\n",
       " torch.Size([72, 72]),\n",
       " tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True]),\n",
       " tensor([[False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mask(seg):\n",
    "    # mask掉<PAD>的位置\n",
    "    key_padding_mask = seg == 0\n",
    "    # encoder不需要attn_mask，定义为全Flase\n",
    "    encode_attn_mask = torch.ones(72, 72) == -1\n",
    "    return key_padding_mask, encode_attn_mask\n",
    "\n",
    "key_padding_mask, encode_attn_mask = get_mask(test_seg)\n",
    "key_padding_mask.shape, encode_attn_mask.shape, key_padding_mask[0], encode_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff8cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2]), torch.Size([32, 72, 12397]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义BERT模型\n",
    "class BERTModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 词向量编码层\n",
    "        self.sent_embed = torch.nn.Embedding(num_embeddings=len(vocab), embedding_dim=256)\n",
    "        # seg编码层\n",
    "        self.seg_embed = torch.nn.Embedding(num_embeddings=3, embedding_dim=256)\n",
    "        # 位置编码层\n",
    "        self.position_embed = torch.nn.Parameter(torch.randn(72, 256) / 10)\n",
    "\n",
    "        # 编码层\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "            nhead=4,\n",
    "            d_model=256,\n",
    "            dim_feedforward=256,\n",
    "            dropout=0.2,\n",
    "            activation='relu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        # 标准化层\n",
    "        norm = torch.nn.LayerNorm(normalized_shape=256, elementwise_affine=True)\n",
    "        # 定义编码器\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=4, norm=norm)\n",
    "\n",
    "        # same输出层\n",
    "        self.fc_same = torch.nn.Linear(in_features=256, out_features=2)\n",
    "        self.fc_sent = torch.nn.Linear(in_features=256, out_features=len(vocab))\n",
    "\n",
    "    def forward(self, sent, seg):\n",
    "        # sent = [b, 72]\n",
    "        # seg = [b, 72]\n",
    "        # 获取mask\n",
    "        # [b, 72] -> [b, 72] [72, 72]\n",
    "        key_padding_mask, encode_attn_mask = get_mask(seg)\n",
    "        # 编码与添加位置信息\n",
    "        embed = self.sent_embed(sent) + self.seg_embed(seg) + self.position_embed\n",
    "        # 编码器计算\n",
    "        memory = self.encoder(src=embed, mask=encode_attn_mask, src_key_padding_mask=key_padding_mask)\n",
    "        # same输出 [b, 2]\n",
    "        same = self.fc_same(memory[:, 0])\n",
    "        # sent输出 [b, 72, V]\n",
    "        sent = self.fc_sent(memory)\n",
    "        return same, sent\n",
    "\n",
    "model = BERTModel()\n",
    "pre_sent, pre_seg = model(test_sent, test_seg)\n",
    "pre_sent.shape, pre_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c39092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 126 7.023106098175049 0.65625 0.10778443113772455\n",
      "5 126 6.793050765991211 0.65625 0.1566265060240964\n",
      "10 126 6.900703430175781 0.5 0.08333333333333333\n",
      "15 126 6.982535362243652 0.78125 0.09239130434782608\n",
      "20 126 6.778187274932861 0.8125 0.07179487179487179\n",
      "25 126 6.534829616546631 0.625 0.11170212765957446\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    for epoch in range(30):\n",
    "        for i, (same, sent, seg) in enumerate(loader):\n",
    "            replace_sent, replace = random_replace(sent)\n",
    "            pred_same, pred_sent = model(replace_sent, seg)\n",
    "            # 提取替换位置的输出\n",
    "            pred_sent = pred_sent[replace]\n",
    "            # 提取替换位置的输入\n",
    "            sent = sent[replace]\n",
    "            # 计算损失\n",
    "            loss_same = loss_func(pred_same, same)\n",
    "            loss_sent = loss_func(pred_sent, sent)\n",
    "            loss = 0.01 * loss_same + loss_sent\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        if epoch % 5 == 0:\n",
    "            pred_same = pred_same.argmax(dim=1)\n",
    "            acc_same = (pred_same == same).sum().item() / len(same)\n",
    "            pred_sent = pred_sent.argmax(dim=1)\n",
    "            acc_sent = (pred_sent == sent).sum().item() / len(sent)\n",
    "            print(epoch, i, loss.item(), acc_same, acc_sent)\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
